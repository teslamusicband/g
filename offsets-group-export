При таком подходе с данными в `__consumer_offsets` произойдет следующее:

## Что случится с данными

**Данные consumer offsets НЕ будут автоматически перенесены** по следующим причинам:

1. **MirrorMaker пропускает системные топики**: По умолчанию все топики, начинающиеся с `__`, исключаются из репликации
2. **Разные coordinator'ы**: Consumer group coordinator'ы привязаны к конкретным broker ID и partition assignments
3. **Внутренний формат**: Данные в `__consumer_offsets` имеют специфический внутренний формат с метаданными кластера

## Детальный анализ процесса

### Текущее состояние
```bash
# Старый кластер - порты 9092, 9093, 9094
# __consumer_offsets содержит позиции всех консьюмер-групп

# Новый кластер - порты 9095, 9096, 9097  
# __consumer_offsets создан с RF=3, но пустой
```

### Что происходит с MirrorMaker
```properties
# Стандартная конфигурация MM2 исключает системные топики
topics.blacklist=.*[\-\.]internal,.*\.replica,__.*

# Даже если принудительно включить:
topics.blacklist=
# Данные не будут корректно интерпретированы новым кластером
```

## Последствия для приложений

**После переключения на новый кластер:**

```bash
# Консьюмеры потеряют свои позиции и поведут себя согласно auto.offset.reset:

# Вариант 1: auto.offset.reset=earliest
# Консьюмеры начнут читать ВСЕ сообщения заново → дублирование данных

# Вариант 2: auto.offset.reset=latest  
# Консьюмеры пропустят все накопленные сообщения → потеря данных

# Вариант 3: auto.offset.reset=none
# Консьюмеры упадут с ошибкой → остановка обработки
```

## Практические решения

### 1. Экспорт/импорт consumer offsets (рекомендуемый)

```bash
# НА СТАРОМ КЛАСТЕРЕ: сохранить позиции всех групп
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
    --list > groups.txt

# Экспорт offsets для каждой группы
while read group; do
    kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
        --group $group --describe \
        --formatter kafka.tools.ConsumerGroupCommand\$OffsetsMessageFormatter \
        > offsets_${group}.json
done < groups.txt

# НА НОВОМ КЛАСТЕРЕ: установить позиции после завершения миграции данных
while read group; do
    kafka-consumer-groups.sh --bootstrap-server localhost:9095 \
        --group $group --reset-offsets --from-file offsets_${group}.json \
        --execute
done < groups.txt
```

### 2. Координированная миграция с downtime

```bash
# 1. Остановить все консьюмеры
# 2. Дождаться завершения MirrorMaker
# 3. Экспортировать offsets со старого кластера  
# 4. Импортировать offsets в новый кластер
# 5. Переключить консьюмеры на новый кластер
# 6. Запустить консьюмеры
```

### 3. Использование внешнего offset management

```bash
# Переключить консьюмеры на manual commit
# и хранить offsets во внешней системе (Redis, DB)
```

## Итоговая рекомендация

**Самый безопасный подход:**
1. Выполнить MirrorMaker для переноса данных топиков
2. В период maintenance window экспортировать consumer offsets
3. Импортировать offsets в новый кластер  
4. Переключить приложения на новый кластер

Это гарантирует, что консьюмеры продолжат обработку с правильных позиций без потери или дублирования данных.
